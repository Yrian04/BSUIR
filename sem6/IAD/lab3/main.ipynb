{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "epochs = 3\n",
                "rate = 0.5 ** 10\n",
                "batch_size = 10\n",
                "metric_kwargs = {\n",
                "    'task': 'multiclass', \n",
                "    'num_classes': 10,\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch, torchvision\n",
                "\n",
                "\n",
                "transform = torchvision.transforms.Compose([\n",
                "    torchvision.transforms.ToTensor(),\n",
                "    torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
                "])\n",
                "\n",
                "train_dataset = torchvision.datasets.mnist.MNIST('.', train=True, transform=transform, download=True)\n",
                "test_dataset = torchvision.datasets.mnist.MNIST('.', train=False, transform=transform, download=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
                "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "class MnistNet(torch.nn.Module):\n",
                "    def __init__(self, *args, **kwargs):\n",
                "        super(MnistNet, self).__init__(*args, **kwargs)\n",
                "        self.layer1 = torch.nn.Sequential(\n",
                "            torch.nn.Conv2d(\n",
                "                1,\n",
                "                32,\n",
                "                kernel_size=5,\n",
                "                stride=1,\n",
                "                padding=2,\n",
                "            ),\n",
                "            torch.nn.ReLU(),\n",
                "            torch.nn.MaxPool2d(\n",
                "                kernel_size=2,\n",
                "                stride=2,\n",
                "            ),\n",
                "        )\n",
                "        self.layer2 = torch.nn.Sequential(\n",
                "            torch.nn.Conv2d(\n",
                "                32,\n",
                "                64,\n",
                "                kernel_size=5,\n",
                "                stride=1,\n",
                "                padding=2,\n",
                "            ),\n",
                "            torch.nn.ReLU(),\n",
                "            torch.nn.MaxPool2d(\n",
                "                kernel_size=2,\n",
                "                stride=2,\n",
                "            ),\n",
                "        )\n",
                "        self.dropout = torch.nn.Dropout()\n",
                "        self.fc1 = torch.nn.Linear(7 * 7 * 64, 1024)\n",
                "        self.fc2 = torch.nn.Linear(1024, 10)\n",
                "    \n",
                "    def forward(self, x):\n",
                "        out = self.layer1(x)\n",
                "        out = self.layer2(out)\n",
                "        out = out.reshape(out.size(0), -1)\n",
                "        out = self.dropout(out)\n",
                "        out = self.fc1(out)\n",
                "        out = self.fc2(out)\n",
                "        return out"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "<All keys matched successfully>"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "model = MnistNet()\n",
                "model.load_state_dict(state_dict=torch.load('conv_net_model.ckpt'))\n",
                "# criterion = torch.nn.CrossEntropyLoss()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "optimizer = torch.optim.Adam(model.parameters(), lr=rate)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "ename": "TypeError",
                    "evalue": "Accuracy.__new__() missing 1 required positional argument: 'task'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[24], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m total_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n\u001b[1;32m      5\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[0;32m----> 6\u001b[0m metric \u001b[38;5;241m=\u001b[39m \u001b[43mtorchmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAccuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n",
                        "\u001b[0;31mTypeError\u001b[0m: Accuracy.__new__() missing 1 required positional argument: 'task'"
                    ]
                }
            ],
            "source": [
                "import torchmetrics\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "metric = torchmetrics.Accuracy()\n",
                "model.train()\n",
                "total_step = len(train_loader)\n",
                "for epoch in range(epochs):\n",
                "    for i, (images, labels) in enumerate(train_loader):\n",
                "        predictions = model(images)\n",
                "        loss = metric(predictions, labels)\n",
                "\n",
                "        optimizer.zero_grad()\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "\n",
                "        if (j := i + 1) % 100 == 0:\n",
                "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.4f}%'.format(epoch + 1, epochs, j, total_step, loss.item(), metric(predictions, labels)))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torchmetrics\n",
                "\n",
                "\n",
                "metrics = {\n",
                "    'accuracy': torchmetrics.Accuracy(**metric_kwargs),\n",
                "    'precision': torchmetrics.Precision(**metric_kwargs),\n",
                "    'recall': torchmetrics.Recall(**metric_kwargs),\n",
                "    'f1-score': torchmetrics.F1Score(**metric_kwargs),\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "---------------- 0\n",
                        "---------------- 1\n",
                        "---------------- 2\n",
                        "---------------- 3\n",
                        "---------------- 4\n",
                        "---------------- 5\n",
                        "---------------- 6\n",
                        "---------------- 7\n",
                        "---------------- 8\n",
                        "---------------- 9\n",
                        "---------------- 10\n",
                        "---------------- 11\n",
                        "---------------- 12\n",
                        "---------------- 13\n",
                        "---------------- 14\n",
                        "---------------- 15\n",
                        "---------------- 16\n",
                        "---------------- 17\n",
                        "---------------- 18\n",
                        "---------------- 19\n",
                        "---------------- 20\n",
                        "---------------- 21\n",
                        "---------------- 22\n",
                        "---------------- 23\n",
                        "---------------- 24\n",
                        "---------------- 25\n",
                        "---------------- 26\n",
                        "---------------- 27\n",
                        "---------------- 28\n",
                        "---------------- 29\n",
                        "---------------- 30\n",
                        "---------------- 31\n",
                        "---------------- 32\n",
                        "1 tensor(2)\n",
                        "Test of the model on the 10000 test images:\n",
                        "\tAccuracy: 0.9972972869873047 %\n",
                        "\tPrecision: 0.9972972869873047 %\n",
                        "\tRecall: 0.9972972869873047 %\n",
                        "\tF1-score: 0.9972972869873047 %\n"
                    ]
                },
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 640x480 with 1 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "\n",
                "\n",
                "model.eval()\n",
                "with torch.no_grad():\n",
                "    correct = 0\n",
                "    total = 0\n",
                "    for i, (images, labels) in enumerate(test_loader):\n",
                "        predictions = model(images)\n",
                "        _, predicted = torch.max(predictions.data, 1)\n",
                "        for metric in metrics.values():\n",
                "            metric(predicted, labels)\n",
                "        \n",
                "        flag = True\n",
                "        print('----------------', i)\n",
                "        for image, prediction, label in zip(images, predictions, labels):\n",
                "            pred = [i for i in prediction].index(max(prediction))\n",
                "            if pred == label:\n",
                "                continue\n",
                "            else:\n",
                "                flag = False\n",
                "                plt.imshow(image.reshape((28,28)))\n",
                "                print([i for i in prediction].index(max(prediction)), label)\n",
                "                break\n",
                "\n",
                "        if not flag:\n",
                "            break\n",
                "        \n",
                "    print(f'Test of the model on the {len(test_dataset)} test images:')\n",
                "    for metric in metrics:\n",
                "        print(f'\\t{metric.capitalize()}: {metrics[metric].compute()} %')\n",
                "\n",
                "\n",
                "# Сохраняем модель и строим график\n",
                "torch.save(model.state_dict(), 'conv_net_model.ckpt')\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
